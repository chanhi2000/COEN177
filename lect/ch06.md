# ch06
FILE SYSTEM

FILE SYSTEMS
- Files
- Directories & naming
- File system implementation 
- Example file systems


LONG-TERM INFORMATION STORAGE
- Must store large amounts of data 
    - Gigabytes ➙ terabytes ➙ petabytes
- Stored information must survive the termination of the process using it
    - Lifetime can be seconds to years 
    - Must have some way of finding it!
- Multiple processes must be able to access the information concurrently


NAMING FILES
- Important to be able to find files after they’re created
- Every file has at least one name
- Name can be
    - Human-accessible:“foo.c”,“my photo”,“Go Slugs!” 
    - Machine-usable: 1138, 8675309
- Case may or may not matter 
    - Depends on the file system
- Name may include information about the file’s contents
    - Certainly does for the user (the name should make it easy to figure out what’s in it!)
    - Computer may use part of the name to determine the file type

TYPICAL FILE EXTENSIONS
￼


FILE STRUCTURES
￼


INTERNAL FILE STRUCTURE
￼



ACCESSING A FILE
- Sequential access
    - Read all bytes/records from the beginning
    - Cannot jump around
        - May rewind or back up, however
    - Convenient when medium was magnetic tape
    - Often useful when whole file is needed
- Random access
    - Bytes (or records) read in any order 
    - Essential for database systems
    - Read can be ...
        - Move file marker (seek), then read or ... 
        - Read and then move file marker


FILE ATTRIBUTES (POSSIBILITIES)
￼


FILE OPERATIONS
- Create: make a new file
- Delete: remove an existing file
- Open: prepare a file to be
- Close: indicate that a file is no longer being accessed
- Read: get data from a file
- Write: put data to a file
- Append: like write, but only at the end of the file
- Seek: move the “current” pointer elsewhere in the file
- Get attributes: retrieve attribute information
- Set attributes: modify attribute information
- Rename: change a file’s name


MEMORY-MAPPED FILES
￼
- Segmented process before mapping files into its address space
- Process after mapping
    - Existing file abc into one segment 
    - Creating new segment for xyz

MORE ON MEMORY-MAPPED FILES
- Memory-mapped files are a convenient abstraction
    - Example: string search in a large file can be done just as with memory!
    - Let the OS do the buffering (reads & writes) in the virtual memory system
- Some issues come up...
    - How long is the file?
        - Easy if read-only
        - Difficult if writes allowed: what if a write is past the end of file?
    - What happens if the file is shared: when do changes appear to other processes? 
    - When are writes flushed out to disk?
- Clearly, easier to memory map read-only files...


DIRECTORIES
- Naming is nice, but limited
- Humans like to group things together for convenience
- File systems allow this to be done with directories (sometimes called folders)
- Grouping makes it easier to
    - Find files in the first place: remember the enclosing directories for the file
    - Locate related files (or just determine which files are related)


SINGLE-LEVEL DIRECTORY SYSTEMS
￼
- One directory in the file system
- Example directory
    - Contains 4 files (foo, bar, baz, blah)
    - owned by 3 different people: A, B, and C (owners shown in red)
- Problem: what if user B wants to create a file called foo?


TWO-LEVEL DIRECTORY SYSTEM
￼
- Solves naming problem: each user has her own directory
- Multiple users can use the same file name
- By default, users access files in their own directories
- Extension: allow users to access files in others’ directories


HIERARCHICAL DIRECTORY SYSTEM
￼


UNIX DIRECTORY TREE
￼


OPERATIONS ON DIRECTORIES
- Create: make a new directory
- Delete: remove a directory (usually must be empty)
- Opendir: open a directory to allow searching it
- Closedir: close a directory (done searching)
- Readdir: read a directory entry
- Rename: change the name of a directory • Similar to renaming a file
- Link: create a new entry in a directory to link to an existing file
- Unlink: remove an entry in a directory
    - Remove the file if this is the last link to this file

FILE SYSTEM IMPLEMENTATION ISSUES
- How are disks divided up into file systems?
- How does the file system allocate blocks to files?
- How does the file system manage free space?
- How are directories handled?
- How can the file system improve... • 
    - Performance?
    - Reliability?


CARVING UP THE DISK
￼


CONTIGUOUS ALLOCATION FOR FILE BLOCKS
￼
- Contiguous allocation requires all blocks of a file to be consecutive on disk
- Problem: deleting files leaves “holes”
    - Similar to memory allocation issues
    - Compacting the disk can be a very slow procedure...


CONTIGUOUS ALLOCATION
￼
- Data in each file is stored in consecutive blocks on disk
- Simple & efficient indexing
    - Starting location (block #) on disk (start)
    - Length of the file in blocks (length)
- Random access well-supported
- Difficult to grow files
    - Must pre-allocate all needed space 
    - Wasteful of storage if file isn’t using all of the space
- Logical to physical mapping is easy
￼



LINKED ALLOCATION
￼
- File is a linked list of disk blocks
    - Blocks may be scattered around the disk drive
    - Block contains both the pointer to next block and data
    - Files may be as long as needed
- New blocks are allocated as needed
    - Linked into list of blocks in file
    - Removed from list (bitmap) of free blocks


FINDING BLOCKS WITH LINKED ALLOCATION
- Directory structure is simple
    - Starting address looked up from directory
    - Directory only keeps track of first block (not others)
- No wasted space—all blocks can be used
- Random access is difficult: must always start at first block!
- Logical to physical mapping is done by 
￼
- Assumes that next pointer is stored at end of block
- May require a long time for seek to random location in file


LINKED ALLOCATION USING A TABLE IN RAM
￼
- Links on disk are slow
- Keep linked list in memory 
- Advantage: faster
- Disadvantages
    - Have to copy it to disk at some point
    - Have to keep in-memory and on-disk copy consistent


USING A BLOCK INDEX FOR ALLOCATION
￼
- Store file block addresses in an array
    - Array itself is stored in a disk block 
    - Directory has a pointer to this disk block
    - Non-existent blocks indicated by –1
- Random access easy
- Limit on file size?


FINDING BLOCKS WITH INDEXED ALLOCATION
- Need location of index table: look up in directory 
- Random & sequential access both well-supported:  look up block number in index table
- Space utilization is good
    - No wasted disk blocks (allocate individually) 
    - Files can grow and shrink easily
    - Overhead of a single disk block per file
- Logical to physical mapping is done by
￼
- Limited file size: 256 pointers per index block, 1 KB per file block ⇒ 256 KB per file limit


LARGER FILES WITH INDEXED ALLOCATION
- How can indexed allocation allow files larger than a single index block?
- Linked index blocks: similar to linked file blocks, but using index blocks instead
- Logical to physical mapping is done by 
￼
- File size is now unlimited
- Random access slow, but only for very large files


TWO-LEVEL INDEXED ALLOCATION
- Allow larger files by creating an index of index blocks 
    - File size still limited, but much larger
    - Limit for 1 KB blocks = 1 KB × 256 × 256 = 226 bytes = 64 MB
- Logical to physical mapping is done by
￼
    - Start is the only pointer kept in the directory
    - Overhead is now at least two blocks per file
- This can be extended to more than two levels if larger files are needed...


BLOCK ALLOCATION WITH EXTENTS
- Reduce space consumed by index pointers
    - Often, consecutive blocks in file are sequential on disk
    - Store <block,count> instead of just <block> in index
    - At each level, keep total count for the index for efficiency
- Lookup procedure is:
    - Find correct index block by checking the starting file offset for each index block
    - Find correct <block,count> entry by running through index block, keeping track of how far into file the entry is
    - Find correct block in <block,count> pair
- More efficient if file blocks tend to be consecutive on disk
    - Allocating blocks like this allows faster reads & writes
    - Lookup is somewhat more complex


MANAGING FREE SPACE:  BIT VECTOR
- Keep a bit vector, with one entry per file block
    - Number bits from 0 through n-1, where n is the number of blocks available for files on the disk
    - If bit[j] == 0, block j is free
    - If bit[j] == 1,block j is in use by a file (for data or index)
- If words are 32 bits long, calculate appropriate bit by: 
￼
- Search for free blocks by looking for words with bits unset (words != 0xffffffff)
- Easy to find consecutive blocks for a single file
- Bit map must be stored on disk, and consumes space
    - Assume 4 KB blocks, 256 GB disk ⇒ 64M blocks 
    - 64M bits = 226 bits = 223 bytes = 8MB overhead


MANAGING FREE SPACE:  LINKED LIST
- Use a linked list to manage free blocks
    - Similar to linked list for file allocation
    - No wasted space for bitmap
    - No need for random access unless we want to find consecutive blocks for a single file
- Difficult to know how many blocks are free unless it’s tracked elsewhere in the file system
- Difficult to group nearby blocks together if they’re freed at different times
    - Less efficient allocation of blocks to files
    - Files read & written more because consecutive blocks not nearby


ISSUES WITH FREE SPACE MANAGEMENT
- OS must protect data structures used for free space management
- OS must keep in-memory and on-disk structures consistent 
    - Update free list when block is removed: change a pointer in the previous block in the free list
    - Update bit map when block is allocated
        - Caution: on-disk map must never indicate that a block is free when it’s part of a file
        - Solution: set bit[j] in free map to 1 on disk before using block[j] in a file and setting bit[j] to 1 in memory
        - New problem: OS crash may leave bit[j] == 1 when block isn’t actually used in a file
        - New solution: OS checks the file system when it boots up... 
- Managing free space is a big source of slowdown in file systems


WHAT IS IN A DIRECTORY?
￼
- Two types of information
    - File names
    - File metadata (size, timestamps, etc.)
- Basic choices for directory information
    - Store all information in directory
        - Fixed size entries
        - Disk addresses and attributes in directory entry 
    - Store names & pointers to index nodes (i-nodes)


DIRECTORY STRUCTURE
- Structure
    - Linear list of files (often itself stored in a file)
        - Simple to program
        - Slow to run
        - Increase speed by keeping it sorted (insertions are slower!)
    - Hash table: name hashed and looked up in file
        - Decreases search time: no linear searches!
        - May be difficult to expand
        - Can result in collisions (two files hash to same location)
    - Tree
        - Fast for searching
        - Easy to expand
        - Difficult to do in on-disk directory
- Name length
    - Fixed: easy to program
    - Variable: more flexible, better for users


SHARING FILES
￼


SOLUTION: USE LINKS
￼
- A creates a file, and inserts into her directory
- B shares the file by creating a link to it
- A unlinks the file
    - B still links to the file
    - Owner is still A (unless B explicitly changes it)


MANAGING DISK SPACE
￼
- Green line (right hand scale) gives data rate of a disk
- Blue line (left hand scale) gives disk space efficiency
- All files 2KB
- Larger blocks are 
    - Faster
    - Less efficient


DISK QUOTAS
￼
- Quotas limit users’ allocation
    - Space might be rented
    - Protect the system from rogue programs allocating space
- Hard limits may not be exceeded
- Soft limits generate warnings
    - Number of warnings may be limited
    - Generate too many warnings ➙ treat as hard limit


BACKING UP A FILE SYSTEM
- Goal: create an extra copy of each file in the file system
    - Protect against disk failure
    - Protect against human error (rm - .o)
    - Allow the system to track changes over time
- Two basic types of backups
    - Full backup: make a copy of every file in the system
    - Incremental backup: only make a copy of files that have changed since the last backup 
        - Faster: fewer files to copy
        - Smaller
- Incremental backups typically require a full backup as a “base”


BACKUP MECHANICS
- Actually copy blocks from one file system to another
￼
    - Safe if original FS fails
    - Safe if original FS is corrupted
    - May be difficult to find modified files
    - Somewhat slow 
- Snapshot
￼
    - New data doesn’t overwrite old data
    - Easy to recover “deleted” files
    - Fast
    - Not as helpful for failed devices or corrupted FS
    - Snapshots can be done with hard links....


FINDING FILES TO BACK UP
- “Walk” the file system tree looking for files modified since the last backup
￼
    - Slow
    - Works on any file system 
- Scan the list of inodes looking for modified files
￼
    - Faster (sequential access)
    - FS-specific code (may require raw disk access) 
- Keep a log of changes the FS makes
￼
    - Can be very fast
    - Requires help from the FS


CHECKING A FILE SYSTEM FOR CONSISTENCY
￼
￼
￼
￼


FILE SYSTEM CACHE
- Many files are used repeatedly
    - Option: read it each time from disk
    - Better: keep a copy in memory
- File system cache
    - Set of recently used file blocks 
    - Keep blocks just referenced
    - Throw out old, unused blocks
        - Same kinds of algorithms as for virtual memory
        - More effort per reference is OK: file references are a lot less frequent than memory references
- Goal: eliminate as many disk accesses as possible!
    -  Repeated reads & writes
    - Files deleted before they’re ever written to disk


FILE BLOCK CACHE DATA STRUCTURES
￼
- Used in BSD for a very long time
- Covered by US Patent 7028023 (filed 9/26/02)
- In Tanenbaum’s book as of 2001...


GROUPING DATA ON DISK
￼
- Trends in disk & memory 
    - Faster CPUs
    - Larger memories
- Result
    - More memory ➔ disk caches can also be larger
    - Increasing number of read requests can come from cache 
    - Thus, most disk accesses will be writes
- LFS structures entire disk as a log
    - All writes initially buffered in memory
    - Periodically write these to the end of the disk log 
    - When file opened, locate i-node, then find blocks
- Issue: what happens when blocks are deleted?


EXT2 & EXT3:  THE LINUX FILE SYSTEM
- Ext2 is the standard Linux file system
    - Similar to BSD’s Fast File System (FFS)
- Ext3 is like Ext2, but with journaling 
    - More on that in a bit...
- Ext2 is designed to be
    - Flexible across a wide range of workloads
    - (Relatively) simple to implement
    - Reliable
    - Usable across a wide range of file system sizes from hundreds of megabytes to terabytes
- Basic design hasn’t changed much in 20 years!


LARGE-SCALE STRUCTURE IN EXT3
￼
- Disk broken into block groups
- Each block group is a (mostly) self-contained unit
    - Files can span block groups, but doesn’t happen often
    - Most information is local to the block group
- Bitmaps must fit into a single file system block, limiting the number of data blocks
- Copies of the superblock and group descriptors are stored in every block group for reliability


GROUP DESCRIPTOR
- One descriptor for each group
- Block numbers for
    - Block bitmap
    - Inode bitmap
    - First inode table block
- Counts (limited to 16 bit integers!) 
    - Free blocks in the group
    - Free inodes in the group
    - Directories in the group
- Each block group has a copy of all group descriptors


MORE ON BLOCK GROUPS
- Block group limited to maximum of blockSize-8 blocks (so block bitmap fits in a single block)
    - Maximum size (8 KB blocks) is 512 MB
    - May have any number of block groups per file system
- Maximum of 64K inodes per block group
- Size of inode region (in blocks) calculated by numInodes / (blockSize / 128)
    - This determines the number of data blocks as well
- All block groups must be the same size


LINUX INODE:  FILE INDEXING
￼


INODE CONTENTS
￼
- Inode contains a file’s metadata
    - Ownership & permissions 
    - Time stamps
    - Block pointers
- Inodes stored in the inode region in the block group 
    - Inode number maps to a particular group / offset for the inode
- Soft link stored in inode if possible (using block pointers)
- File “hole”: missing blocks in the middle of a large file


MORE ON UNIX FFS AND LINUX
- First few block pointers kept in directory
    - Small files have no extra overhead for index blocks
    - Reading & writing small files is very fast!
- Indirect structures only allocated if needed
- For 4 KB file blocks (common in Unix), max file sizes are:
    - 48 KB in directory (usually 12 direct blocks)
    - 1024 × 4 KB = 4 MB of additional file data for single indirect
    - 1024 × 1024 × 4 KB = 4 GB of additional file data for double indirect
    - 1024 × 1024 × 1024 × 4 KB = 4TB for triple indirect
- Maximum of 5 accesses for any file block on disk
    - 1 access to read inode & 1 to read file block
    - Maximum of 3 accesses to index blocks
    - Usually much fewer (1–2) because inode in memory


LINUX DIRECTORIES
￼
- Linux supports
    - Plain text directories
    - Hashed directories
    - Plain text more common, but slower
- Directories just like regular files
- Name length limited to 255 bytes
- Hashed directories
    - Use extendible hashing to make lookup faster
    - May be “sparse”


MAJOR ISSUES:  CONSISTENCY
- Creating a file can require 5 disk writes
    - A crash in the middle can leave the file system in an inconsistent state
    - Example: inode allocated, but not inserted into directory
- This is unacceptable!
- Solution: use journaling, as provided in Ext3
- Problem: what do you journal? 
    - Metadata and data?
    - Metadata only?
        - This introduces an ordering constraint
        - Data must be written before metadata is written


JOURNALING IN EXT3
- Ext3 uses a journal to record operations before they are written to disk
- 3 journaling modes
    - Journal: record everything to the journal
        - Slowest
        - Records data and metadata as soon as they’re written
    - Ordered: record only metadata, but order data and metadata writes so there’s no inconsistency
        - Faster
        - Less safe: metadata updates not committed immediately 
        - Default mode for Ext3
    - Metadata only: record only metadata - Not as safe as other two
        - Fastest of the three


EXT3 JOURNAL DETAILS
- Log record: basic entry in journal 
    - One per disk request
    - Span of bytes, or entire block
- Atomic operation handle: used to group log records together
    - Typically, one handle corresponds to a single system call 
    - Ensures that high-level operation either completes or never happens (no partial operations)
- Transaction: consists of multiple atomic operations 
    - Done for efficiency reasons
    - Entire transaction written out at once
    - Only one transaction “open” at any time


CD-ROM FILE SYSTEM
￼
- File catalog in first few blocks of disk
    - Lists all files on the CD
    - Hierarchical structure can be built by treating files as directories (ISO 9660)
- Files all allocated contiguously
    - No need to handle overwrites...


MS-DOS (FAT) FILE SYSTEM
￼
- Originally designed for floppy disks
    - Adapted to small (5 MB) hard drives
    - Commonly used for flash drives
- Single list of blocks in use (FAT = File Allocation Table) 
    - Fixed overhead per block
    - Easy to find all blocks in a file
- Root directory “file” starts in block 0
    - Other files have first block number in directory entry


MS-DOS FILE ALLOCATION TABLE
￼

DIRECTORY ENTRY IN MS-DOS
￼

WIN98 DIRECTORY ENTRY & FILE NAME
￼


STORING A LONG NAME IN WINDOWS 98
￼
- Long name stored in Windows 98 so that it’s backwards compatible with short names
    - Short name in “real” directory entry
    - Long name in “fake” directory entries: ignored by older systems
- OS designers will go to great lengths to make new systems work with older systems...